---
title: "Модуль upmeter"
---

Модуль собирает статистику по типам доступности для компонентов кластера и Deckhouse. Позволяет оценивать степень выполнения SLA на эти компоненты, показывает данные о доступности в web-интерфейсе и предоставляет web-страницу статуса работы компонентов кластера.

С помощью Custom Resource [UpmeterRemoteWrite](cr.html#upmeterremotewrite) можно экспортировать метрики доступности по протоколу [Prometheus Remote Write](https://docs.sysdig.com/en/docs/installation/prometheus-remote-write/).

Состав модуля:
- **agent** — делает пробы доступности и отправляет результаты на сервер, работает на мастер-узлах.
- **upmeter** — агрегатор результатов и API-сервер для их извлечения.
- **front**
  - **status** — показывает текущий уровень доступности за последние 10 минут (по умолчанию требует авторизации, но её можно отключить).
  - **webui** — дашборд со статистикой по пробам и группам доступности (требует авторизации).
- **smoke-mini** — постоянное *smoke-тестирование* с помощью StatefulSet, похожего на настоящее приложение.

Модуль отправляет около 100 показаний метрик каждые 5 минут. Это значение зависит от количества включенных модулей Deckhouse.

## Интерфейс

Пример web-интерфейса:
![Пример web-интерфейса](../../images/500-upmeter/image1.png)

Пример графиков по метрикам из upmeter в Grafana:
![Пример графиков по метрикам из upmeter в Grafana](../../images/500-upmeter/image2.png)


## Концепция

### Термины

Агенты апметра `ds/upmeter-agent` собирают данные, запуская пробы. Каждые 30 секунд агенты отправляют на сервер `sts/upmeter` статистику доступности для проб и групп проб.

**Проверка** (check) — это единица получения данных из кластера.

**Проба** (probe) — это единица сбора статистики доступности фичи. Проба может состоять из нескольких проверок.

**Группа доступности** (availablility group, group) — это группа проб объединенная по принципу функциональности. Группа состоит из одной или более проб.  По группе оценивается доступность и соблюдение SLA согласно условиям соглашения.

Если за интервал измерения в пробе не прошла хотя бы одна проверка, то проба принимает
соответствующий статус. Успешно прошедшие пробы игнорируются. Группа принимает статус самой
неудачной пробы.

Статус проверки → статус пробы → статусы групп:

* **Up** — проверка доступности положительная
* **Down** — проверка доступности отрицательная
* **Unknown** — данные собирались, но не смогли вынести вердикт доступности
* **Nodata** — данные не собирались, например если upmeter-agent не работал

Пример для статуса *Unknown*. Перед проверкой статуса пода (Ready или нет), делается проверка доступности аписервера — запрос на /version, как в пробе control-plane/apiserver. Если версию аписервера получить не удалось, проверка пода возвращает статус *Unknown*, потому что статус пода узнать невозможно.

### Алгоритмы вычисления доступности

Если проверки одной пробы завершились с разными статусами, то статус этой пробы вычисляется принципу наименьшего значения при отношении

  Down < Up < Unknown

Проба получит статус *Unknown*, если все проверки завершились с этим статусом. Если хотя бы одна проверка завершилась с *Up* и ни одной — с *Down*, то статус пробы будет *Up*. Если хотя бы одна проверка завершилась со статусом *Down*, то статус пробы будет *Down*.

Таким же способом складывается статус группы на основе статусов проб.

Агенты апметра отправляют статистику доступности за 30 секунд на сервер. Интервалы накоплений
выбираются по системным часам кратно 30 секундам текущего времени. 30 секунд — это оперативный
интервал. Статистика для групп вычисляется в агенте и отправляется на сервер совместно со
статистикой для проб

Сервер комбинирует статистику от нескольких агентов по принципу самой удачной в интервал 5 минут. 5
минут — это интервал хранения данных и отправки метрик.

Как статус группы зависит от статуса проб:

  * Если хотя бы одна проба в группе имеет статус *Down*, то статус группы *Down*
  * Если хотя бы одна проба в группе имеет статус *Unknown*, то статус группы *Unknown*
  * Если все пробы в группе имеют статус *Up*, то статус группы *Up*

### Сбор статистики статусов

Агенты апметра отправляют собирают статистику доступности за интервал накопления 30 секунд и
отправляют ее на сервер. Агент запускает проверки и записывает статусы проб в промежуточную таблицу,
причем статусы проб вычисляются перед записью в таблицу. Каждые 200 мс (интервал самой частой проверки)
агент собирает срез статусов и наполняет массивы статусов для каждой пробы.

Если проверка запускается с интервалом 5 секунд, то за 30 секунд будет 6 запусков и, соответственно,
6 обновлений статуса. При этом в массиве статусов будет 150 элементов (200 мс в 30 секундах). Из них
вычисляется статистика статусов в единицах времени.

Пример массива статусов, без привязки к конкреным параметрам времени:

```
                     |------------ интервал накопления -----------|
запуск проверки      ↓_________     ↓_________     ↓_________     |
статус проверки   nd>_________up_____________dn_____________up____|
                              ↓              ↓              ↓
срез nodata          nd nd nd
срез up                       up up up up up                up up
срез down                                    dn dn dn dn dn
запуск среза         ↑__↑__↑__↑__↑__↑__↑__↑__↑__↑__↑__↑__↑__↑__↑__
массив статусов      nd nd nd up up up up up dn dn dn dn dn up up
```

Срезы по статусам разделены для наглядности. Статистика за период содержит счетчики времени в
миллисекундах. Если частота среза в примере 200 мс, то статистика получится будет такой:

* up: 7×200 = 1400 мс
* down (dn): 5×200 = 1000 мс
* nodata (nd): 2×200 = 600 мс
* unknown: 0

Статус *Nodata*  возникает, когда агент запускается не идеально в начале интервала накопления,
поэтому в начале интервала накопления не было измерений.

Массив статусов группы вычисляется из массивов статусов проб в этой группе. Может получится так, что
две пробы будут иметь статус *Down* в разное время. Тогда статистика доступности у группы будет
хуже, чем у каждой из проб. Наглядно пример этой ситуации можно проследить на массивах (*Down*
выделено как *DN* для наглядности):

```
             Массивы статусов                                Доступность up/(up+dn)
проба 1      up up up up DN DN DN DN up up up up up up up    11/15 = 0.73
проба 2      up up up up up up DN DN DN DN DN up up up up    10/15 = 0.67
группа       up up up up DN DN DN DN DN DN DN up up up up     8/15 = 0.53
```

## Метрики

Апметр отправляет данные по протоколу rewmote_write. Так как он копит статистику доступности за 5 минут, то и экспортирует это значение раз в 5 минут. Поэтому в метриках такой интервал между сэмплами.

Метрика называется *status_time* — это время одного статуса за период 5 минут. Статусы в метриках
есть для индивидуальных проб и для групп целиком. Сумма статусов для пробы или группы — всегда пять
минут. Единицы значений — миллисекунды.

Пример метрик для пробы и группы целиком:

```promql
# Пример для группы
status_time{group="synthectic", probe="dns", status="up"}        # ≤ 300000

# Пример для пробы
status_time{group="synthectic", probe="__total__", status="up"}  # ≤ 300000
```

> **Пример.** Возьмем для простоты только статусы *up* и *down*. В пяти минутах 300000 миллисекунд, в этих единицах приходит значение. Допустим, в точке метрики пришли значения с лейблами
> >
> ```
> 100000 status=down
> 200000 status=up
> ```
>
> Тогда
>
> ```
> availability = up/(down+up) = ⅔ = 66%
> ```

— это доступность группы или пробы за 5 минут.


Апметр оценивает время не-простоя с использоваением статуса *Unknown*: делит время «не-простоя» на
все измеренное время.

    availability = (up+unknown)/(down+up+unknown)


## Группы доступности и пробы

Бо̀льшая часть проверок доступности состоит из запросов к API-сервреру кластера. В этих проверках предварительно проверяется доступность API-сервера запросом на /version. Если апи-сервер недоступен, проверка завершается в статусе *Unknown*.

### Группа control-plane

#### apiserver

Проверяет доступность kube-apiserver. Делает запрос на /version.

Интревал: 5 секунд

#### basic-functionality

Проверяет работоспособность kube-apiserver на цикле жизни ConfigMap. Создает ConfigMap, удостоверятся в ее наличии, удаляет ConfigMap, проверяет, что ее нет.

Предварительно проверяет доступность аписервера. Если аписервер недоступен, статус пробы становится *Unknown*.

Интревал: 5 секунд

#### namespace

Проверяет работоспособность kube-apiserver на цикле жизни Namespace. Создает Namespace, удостоверятся в его наличии, удаляет Namespace, проверить что его нет.

Предварительно проверяет доступность аписервера. Если аписервер недоступен, статус пробы становится *Unknown*.

Интревал: 1 минута

#### controller-manager

Проверяет работосопосбность kube-controller-manager на жизненном цикле пода контроллера. Создает StatefulSet, проверяет что создался Pod (его состояние нам не важно, может оставаться в статусе Pending). Удаляет StatefulSet, проверяет Pod удалился.

Предварительно проверяет доступность аписервера. Если аписервер недоступен, статус пробы становится *Unknown*.

Интревал: 1 минута

#### scheduler

Проверяет работоспособность kube-scheduler. Создет Pod и проверяет заполенность поля `.spec.nodeName`.

Предварительно проверяет доступность аписервера. Если аписервер недоступен, статус пробы становится *Unknown*.

Интревал: 1 минута

### Группа deckhouse

#### cluster-configuration

Проверяет работу конфигурации кластера. Декхаус управляет конфигурацией за счет хуков, поэтому эта проба проверяет работу хука.

Для этой пробы существует CRD UpmeterHookProbe. Апметр создаает CR UpmeterHookProbe, если его нет, по одному на каждый Pod upmeter-agent.

В CR апметр перезаписывает поле `spec.initial` случайным значением и ждет, пока поле `spec.mirror` станет равным этому же значению. Хук Декхауса дублирует значение из этого поля в поле `spec.mirror`. Если значение синхронизируется за 30 секунд, проба принимает статус Up.

Период: 1 минута. Предварительно проверяет доступность аписервера. Если аписервер недоступен, статус пробы становится *Unknown*.

Предварительно проверяет статус пода Декхауса:

  - если статус пода Terminating, статус пробы становится *Unknown*,
  - если статус пода Running, но не Ready менее 20 минут, статус пробы становится *Unknown*,
  - если статус пода Running, но не Ready более 20 минут, статус пробы становится *Down*.

### Группа extensions

#### cluster-autoscaler

Проверяет, что хотя бы 1 под cluster-autoscaler в состоянии Ready

Интервал: 10 секунд

#### cluster-scaling

Состоит из трех независимых проверок. Проверяет, что хотя бы 1 под в состоянии Ready у деплойментов machine-controller-manager, cloud-controller-manager, bashible-apiserver

Интервал: 10 секунд. Предварительно проверяет доступность аписервера в каждой проверке. Если аписервер недоступен, статус пробы становится *Unknown*.


#### grafana

Проверяет, что хотя бы 1 под Grafana в состоянии Ready.

Интервал: 10 секунд. Предварительно проверяет доступность аписервера.

#### openvpn

Проверяет, что хотя бы 1 под OpenVPN в состоянии Ready

Интервал: 10 секунд

#### prometheus-longterm

Состоит из двух проверок:

- хотя бы 1 под StatefulSet prometheus-longterm в состоянии Ready
- API отвечает "1" через сервис на запрос /api/v1/query?query=vector(1)

Интервал обеих проверок: 10 секунд.

#### dashboard

Хотя бы 1 под Dashboard в состоянии Ready

Интервал: 10 секунд

#### dex

Состоит из двух проверок:

- хотя бы 1 под Dex в состоянии Ready
- API отвечает через сервис на запрос /keys

Интервал обеих проверок: 10 секунд.

### Группа load-balancing

#### load-balancer-configuration

Хотя бы 1 под cloud-controller-manager в состоянии Ready

Интервал: 10 секунд

#### metallb

Состоит из двух проверок:

- хотя бы 1 под MetalLB Controller в состоянии Ready
- хотя бы 1 под MetalLB Speaker в состоянии Ready

Интервал обеих проверок: 10 секунд.

### Группа monitoring-and-autoscaling

#### prometheus

Состоит из двух проверок:

- хотя бы 1 под StatefulSet prometheus-main в состоянии Ready
- API отвечает "1" через сервис на запрос /api/v1/query?query=vector(1)

Интервал обеих проверок: 10 секунд.

#### trickster

Состоит из двух проверок:

- хотя бы 1 под Deployment trickster в состоянии Ready
- API отвечает "1" через сервис на запрос /trickster/main/api/v1/query?query=vector(1)

Интервал обеих проверок: 10 секунд.

#### prometheus-metrics-adapter

Состоит из двух проверок:

- хотя бы 1 под Deployment prometheus-metrics-adapter в состоянии Ready
- API отвечает "1" через сервис на запрос /apis/custom.metrics.k8s.io/v1beta1/namespaces/d8-upmeter/metrics/memory_1m

Интервал обеих проверок: 5 секунд.

#### vertical-pod-autoscaler

Состоит из трех независимых проверок.  Проверяет, что хотя бы 1 под в состоянии Ready у деплойментов vpa-updater, vpa-recommender, vpa-admission-controller.

Интервал: 10 секунд.

#### metric-sources

Node-exporter (all desired pods are ready)
на всех нодах, где должны быть поды, они есть и они все в состоянии Ready
Не учитываются ноды
которым меньше 10 минут
которые в процессе удаления (deletionTimestamp)
Закордоненные
раз в 10 секунд
kube-state-metrics (хотя бы 1 pod Ready)
раз в 10 секунд

#### key-metrics-present

в prometheus есть метрики от kube-state-metrics
раз в 15 секунд
в prometheus есть метрики от node-exporter
раз в 15 секунд
в prometheus есть метрики от kubelet
раз в 15 секунд

#### Horizontal-pod-autoscaler (вычисляемая проба)
прошли все проверки для проб
monitoring-and-autoscaling/prometheus-metrics-adapter
control-plane/controller-manager

### Группа Nginx
Пробы создаются динамически для имеющихся контроллеров

[имя контролллера]
Pod ready
Раз в 5 секунд

### Группа Node Groups
Пробы создаются динамически для нод-групп, у которых NG.spec.CloudInstances.minPerZone > 0

[имя группы узлов]
Количество узлов в нод-группе соответствует ожидаемому в каждой зоне
Раз в 10 секунд

### Группа Synthetic

**Задача.** Проверить сетевую связность между нодами, покрывая все пары со временем в случайном порядке.

**Как работает.** Проверяется связность как между 5 подами smoke-mini, так и с подами upmeter-agent,
работающих на мастерах. Раз в минуту один из подов smoke-mini переносится на другую ноду. Максимум
задействованы 8 узлов: 3 мастера и 5 не-мастеров.

Смок-мини не масштабируется с размером кластера. Поэтому для больших кластеров он не приносит
оперативную информацию. Недоступность сети подов у малого количества узлов в большом кластере имеем
слабый эффект на статус пробы.

#### access

хотя бы один pod smoke-mini, который отвечает 200кой. Список pod’ов берется из DNS.
раз в 5 секунд
dns
smoke, хотя бы один pod smoke-mini отвечает 200кой на /dns. Он резолвит “kubernetes.default”
раз в 200 миллисекунд
Internal, upmeter-agent резолвит внутренний домен kubernetes.default.svc.<<global.discovery.clusterDomain>>
раз в 200 миллисекунд
neighbour
хотя бы один pod smoke-mini отвечает 200кой на /neighbor.
Список pod’ов берется из DNS.
smoke-mini опрашивает соседние поды по имени Headless сервиса
раз в 5 секунд
neighbour-via-service
хотя бы один pod smoke-mini отвечает 200кой на /neighbour-via-service
Список pod’ов берется из DNS.
Smoke-mini делает 4 запроса на общий сервис ClusterIP и отвечает 200, если было не больше 2 ошибок
раз в 5 секунд
